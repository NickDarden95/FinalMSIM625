{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["BFdaNR0tkHb-","rdVod4aSoQll","AWckO7YQyTYx"],"authorship_tag":"ABX9TyPYjTQUN95IXEVdStEcNb/3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#==========================================================================================\n","#   Jupyter Notebook: Commercial Flight Safety Analysis & Plotting\n","#   Date: 4/20/2025S\n","\n","#   This notebook combines:\n","#     1) Analysis:\n","#        - Loads data\n","#        - Cleans/Explodes/Filters\n","#        - Computes SeverityScore\n","#        - Runs ANOVA\n","#        - Saves processed CSV outputs\n","\n","#     2) Plotting:\n","#        - Reads the CSV outputs\n","#        - Produces time-trend plots, distribution plots, and choropleth maps\n","#        - Allows interactive selection of factors for a violin plot & stacked bar chart\n","\n"],"metadata":{"id":"6ML1Rp3fhUZ7"}},{"cell_type":"markdown","source":["#==========================================================================================\n","# 1) Setup and Imports"],"metadata":{"id":"i1KjRAAHuaCa"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import statsmodels.api as sm\n","from statsmodels.formula.api import ols\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","\n","%matplotlib inline\n","\n","csv_path = \"cases2025-03-25_23-11.csv\"\n","allfights = \"us_total_flight_operations_2005_2025_filtered.csv\"\n","\n","df = pd.read_csv(csv_path)\n","fdf = pd.read_csv(allfights)"],"metadata":{"id":"q74Vl2oih2-Y","executionInfo":{"status":"error","timestamp":1744850723673,"user_tz":360,"elapsed":17464,"user":{"displayName":"Nicholas Darden","userId":"15963773907732293009"}},"colab":{"base_uri":"https://localhost:8080/","height":339},"outputId":"6188edfe-8820-4b81-c74f-a1c5d4af1515"},"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'cases2025-03-25_23-11.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-2da81322d7be>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mallfights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"us_total_flight_operations_2005_2025_filtered.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mfdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallfights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cases2025-03-25_23-11.csv'"]}]},{"cell_type":"markdown","source":["#==========================================================================================\n","# 2) Define Helper Functions\n","\n","These functions exist as a method to break apart columns that contain multiple aircraft in an incident as a way to parse out each individual aircraft for analysis.\n","\n","\n","\n"],"metadata":{"id":"BFdaNR0tkHb-"}},{"cell_type":"code","source":["\n","def split_multi_value_columns(row, columns):\n","    row_dict = row.to_dict()\n","    split_lists = []\n","    for col in columns:\n","        original_value = row_dict.get(col, \"\")\n","        if pd.isna(original_value):\n","            original_value = \"\"\n","        val_str = str(original_value)\n","        if \",\" in val_str:\n","            items = [x.strip() for x in val_str.split(\",\")]\n","        else:\n","            items = [val_str]\n","        split_lists.append(items)\n","    max_len = max(len(lst) for lst in split_lists)\n","    exploded_rows = []\n","    for i in range(max_len):\n","        new_row = dict(row_dict)\n","        for col, items in zip(columns, split_lists):\n","            new_value = items[i] if i < len(items) else \"\"\n","            new_row[col] = new_value\n","        exploded_rows.append(new_row)\n","    return exploded_rows\n","\n","def explode_by_columns(df, multi_cols):\n","    all_exploded_rows = []\n","    for _, row in df.iterrows():\n","        exploded = split_multi_value_columns(row, multi_cols)\n","        all_exploded_rows.extend(exploded)\n","    return pd.DataFrame(all_exploded_rows)"],"metadata":{"id":"wzHaAiHgiov6","executionInfo":{"status":"aborted","timestamp":1744850723675,"user_tz":360,"elapsed":3,"user":{"displayName":"Nicholas Darden","userId":"15963773907732293009"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3) Define columns to parse out for analysis.\n","\n","Print headers for reference."],"metadata":{"id":"Fxx937_Bmz-d"}},{"cell_type":"code","source":["    print(df.head(0))"],"metadata":{"id":"CBCbAs1am_8W","executionInfo":{"status":"aborted","timestamp":1744850723677,"user_tz":360,"elapsed":1,"user":{"displayName":"Nicholas Darden","userId":"15963773907732293009"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Choose Column to break out."],"metadata":{"id":"Fl6rhr0Kn0kN"}},{"cell_type":"code","source":["explode_cols = [\"N#\", \"NumberOfEngines\"]"],"metadata":{"id":"iBAqfxvVoAjq","executionInfo":{"status":"aborted","timestamp":1744850723677,"user_tz":360,"elapsed":8402,"user":{"displayName":"Nicholas Darden","userId":"15963773907732293009"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Choose factors of interest for ANOVA testing and further visualization"],"metadata":{"id":"f3IzMgoislNI"}},{"cell_type":"code","source":["factors = [\n","    \"BroadPhaseAggregate\",\n","    \"WeatherCondition\",\n","    \"FindingsAggregate\",\n","    \"State\",\n","    \"City\",\n","    \"Make\",\n","    \"Model\",\n","    \"Operator\"\n","]"],"metadata":{"id":"9EUynGY7s1Ev","executionInfo":{"status":"aborted","timestamp":1744850723678,"user_tz":360,"elapsed":8403,"user":{"displayName":"Nicholas Darden","userId":"15963773907732293009"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Choose columns to exclude in anlaysis for efficency."],"metadata":{"id":"hjTQUr4Boouq"}},{"cell_type":"code","source":["excluded = [\n","    \"EventType\", \"Mkey\", \"Country\", \"SerialNumber\", \"HasSafetyRec\",\n","    \"Mode\", \"OriginalPublishedDate\", \"DocketOriginalPublishedDate\",\n","    \"Latitude\", \"Longitude\", \"EventID\", \"AmateurBuilt\", \"EngineType\",\n","    \"Scheduled\", \"ReportStatus\", \"RepGenFlag\", \"MostRecentReportType\",\n","    \"DocketUrl\", \"ReportNO\", \"ReportType\"\n","]"],"metadata":{"id":"FckB_xXJoySE","executionInfo":{"status":"aborted","timestamp":1744850723679,"user_tz":360,"elapsed":8404,"user":{"displayName":"Nicholas Darden","userId":"15963773907732293009"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#==========================================================================================\n","# 4) Main Analysis\n","This block applies the fields specified above to the dataset, normalizes the data by applying a severity value to each incident and finally conducts an ANOVA test on the selected factors to determine the statistical significance of each selected factor.\n","\n","\"Severity\" is calculated by summing all recorded levels of injury in an incident multiplied by their recepetive value.\n","<br>Severity Value:<br>\n","FATAL   - 0.75<br>\n","SERIOUS - 0.50<br>\n","MINOR   - 0.25<br>\n","NONE    - 0.00"],"metadata":{"id":"rdVod4aSoQll"}},{"cell_type":"code","source":["excluded_lower = [kw.lower() for kw in excluded]\n","columns_to_drop = [col for col in df.columns if col.lower() in excluded_lower]\n","df_filtered = df.drop(columns=columns_to_drop).fillna(\"\")\n","\n","df_exploded = explode_by_columns(df_filtered, explode_cols)\n","\n","df_exploded = df_exploded[\n","    df_exploded[\"FAR\"].str.contains(\"121\", case=False, na=False) |\n","    df_exploded[\"FAR\"].str.contains(\"135\", case=False, na=False)\n","]\n","df_exploded[\"Year\"] = pd.to_datetime(df_exploded[\"EventDate\"], errors=\"coerce\").dt.year\n","\n","# Fill injury-level\n","df_exploded[\"HighestInjuryLevel\"] = (\n","    df_exploded[\"HighestInjuryLevel\"]\n","    .replace(\"\", np.nan)\n","    .fillna(\"No Injury\")\n",")\n","\n","# Merge with flight ops for incident counts\n","incidents_per_year = df_exploded.groupby(\"Year\").size().reset_index(name=\"Incidents\")\n","merged = pd.merge(incidents_per_year, fdf, on=\"Year\", how=\"left\").fillna(0)\n","\n","merged[\"Total Commercial Flights\"] = merged[\"Air Carrier\"] + merged[\"Air Taxi\"]\n","merged[\"Incidents per Million Flights\"] = (\n","    merged[\"Incidents\"] / merged[\"Total Commercial Flights\"] * 1_000_000\n",")\n","\n","# Compute Severity Score\n","for col in [\"FatalInjuryCount\", \"SeriousInjuryCount\", \"MinorInjuryCount\"]:\n","    df_exploded[col] = (\n","        pd.to_numeric(df_exploded[col], errors='coerce')\n","        .fillna(0)\n","        .astype(float)\n","    )\n","\n","df_exploded[\"SeverityScore\"] = (\n","    df_exploded[\"FatalInjuryCount\"] * 0.75\n","    + df_exploded[\"SeriousInjuryCount\"] * 0.5\n","    + df_exploded[\"MinorInjuryCount\"] * 0.25\n",")\n","\n","# Aggregate broad phase of flight\n","aggregation_map = {\n","    \"Initial Climb\":    \"Takeoff/Departure\",\n","    \"Takeoff\":          \"Takeoff/Departure\",\n","    \"Approach\":         \"Landing/Arrival\",\n","    \"Landing\":          \"Landing/Arrival\",\n","    \"After Landing\":    \"Landing/Arrival\",\n","    \"Enroute\":          \"Mid-Flight\",\n","    \"Maneuvering\":      \"Mid-Flight\",\n","    \"Standing\":         \"Ground Operations\",\n","    \"Pushback/Tow\":     \"Ground Operations\",\n","    \"Taxi\":             \"Ground Operations\"\n","}\n","df_exploded[\"BroadPhaseAggregate\"] = (\n","    df_exploded[\"BroadPhaseofFlight\"].map(aggregation_map).fillna(\"Unknown\")\n",")\n","\n","# Drop single-engine aircraft\n","df_exploded = df_exploded[df_exploded[\"NumberOfEngines\"] != \"1\"].copy()\n","\n","# Assign State Abbreviations & drop rows not in the dictionary\n","state_name_to_abbrev = {\n","    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\",\n","    \"California\": \"CA\", \"Colorado\": \"CO\", \"Connecticut\": \"CT\", \"Delaware\": \"DE\",\n","    \"District of Columbia\": \"DC\", \"Florida\": \"FL\", \"Georgia\": \"GA\", \"Hawaii\": \"HI\",\n","    \"Idaho\": \"ID\", \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\", \"Kansas\": \"KS\",\n","    \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \"Maryland\": \"MD\",\n","    \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\",\n","    \"Missouri\": \"MO\", \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\",\n","    \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\", \"New Mexico\": \"NM\", \"New York\": \"NY\",\n","    \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \"Ohio\": \"OH\", \"Oklahoma\": \"OK\",\n","    \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\",\n","    \"South Dakota\": \"SD\", \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\",\n","    \"Vermont\": \"VT\", \"Virginia\": \"VA\", \"Washington\": \"WA\", \"West Virginia\": \"WV\",\n","    \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\"\n","}\n","\n","df_exploded.loc[:, \"StateAbbrev\"] = df_exploded[\"State\"].map(state_name_to_abbrev)\n","df_exploded = df_exploded.dropna(subset=[\"StateAbbrev\"])\n","\n","# Save key CSV outputs\n","merged.to_csv(\"incidents_normalized.csv\", index=False)\n","\n","severity_by_ntsb = (\n","    df_exploded.drop_duplicates(\"NtsbNo\")\n","    .groupby(\"Year\")[\"SeverityScore\"]\n","    .agg([\"mean\", \"sum\"])\n","    .reset_index()\n",")\n","severity_by_ntsb = pd.merge(severity_by_ntsb, fdf, on=\"Year\", how=\"left\").fillna(0)\n","severity_by_ntsb[\"Total Commercial Flights\"] = (\n","    severity_by_ntsb[\"Air Carrier\"] + severity_by_ntsb[\"Air Taxi\"]\n",")\n","severity_by_ntsb[\"Severity per Million Flights\"] = (\n","    (severity_by_ntsb[\"sum\"] / severity_by_ntsb[\"Total Commercial Flights\"])\n","    .fillna(0)\n","    * 1_000_000\n",")\n","severity_by_ntsb.to_csv(\"severity_by_year.csv\", index=False)\n","df_exploded.to_csv(\"filtered_cases.csv\", index=False)\n","\n","# Parse out \"Findings\" + create aggregated factor columns\n","factor_substring_map = {\n","    \"control parameters\": \"control parameters\",\n","    \"turbulence\":         \"turbulence\",\n","    \"landing gear\":       \"landing gear\",\n","    \"aircraft control\":   \"aircraft control\",\n","    \"power plant\":        \"power plant\",\n","    \"psychological\":      \"psychological\",\n","    \"maintenance\":        \"maintenance\",\n","    \"animal\":             \"animal\",\n","    \"Pilot\":              \"Pilot\",\n","    \"Crew Proficency\":    \"Task performance\"\n","}\n","\n","if \"Findings\" in df_exploded.columns:\n","    for sub_label in factor_substring_map:\n","        df_exploded[sub_label] = (\n","            df_exploded[\"Findings\"]\n","            .str.contains(factor_substring_map[sub_label], case=False, na=False)\n","            .astype(int)\n","        )\n","else:\n","    print(\"WARNING: 'Findings' column not found in df_exploded.\")\n","\n","def aggregate_findings(row):\n","    active_labels = []\n","    for k in factor_substring_map:\n","        if row[k] == 1:\n","            active_labels.append(k)\n","    return \",\".join(active_labels) if active_labels else \"None\"\n","\n","df_exploded[\"FindingsAggregate\"] = df_exploded.apply(aggregate_findings, axis=1)\n","\n","anova_results = []\n","ranking_results = []\n","\n","for factor in factors:\n","    sub = df_exploded.dropna(subset=[\"SeverityScore\", factor]).copy()\n","    if sub.empty:\n","        continue\n","\n","    unique_vals = sub[factor].unique()\n","    if len(unique_vals) < 2:\n","        continue\n","\n","    sub[factor] = sub[factor].astype(\"category\")\n","    formula = f\"SeverityScore ~ C({factor})\"\n","    model = ols(formula, data=sub).fit()\n","    anova_table = sm.stats.anova_lm(model, typ=2)\n","\n","    F_value = anova_table.loc[f\"C({factor})\", \"F\"]\n","    p_value = anova_table.loc[f\"C({factor})\", \"PR(>F)\"]\n","\n","    anova_results.append({\n","        \"Factor\": factor,\n","        \"NumCategories\": len(unique_vals),\n","        \"F_value\": F_value,\n","        \"p_value\": p_value\n","    })\n","\n","    group_means = (\n","        sub.groupby(factor, observed=False)[\"SeverityScore\"]\n","        .mean()\n","        .reset_index()\n","        .rename(columns={\"SeverityScore\": \"MeanSeverityScore\"})\n","    )\n","    group_means = group_means.sort_values(\"MeanSeverityScore\", ascending=False)\n","    group_means.insert(0, \"Factor\", factor)\n","    ranking_results.append(group_means)\n","\n","anova_df = pd.DataFrame(anova_results)\n","anova_df = anova_df.sort_values(\"p_value\", ascending=True).reset_index(drop=True)\n","anova_df.to_csv(\"anova_overall_results.csv\", index=False)\n","print(\"Saved overall ANOVA results to anova_overall_results.csv.\")\n","\n","if ranking_results:\n","    ranking_final = pd.concat(ranking_results, ignore_index=True)\n","    ranking_final.to_csv(\"group_mean_ranking_by_factor.csv\", index=False)\n","    print(\"Saved group mean ranking results to group_mean_ranking_by_factor.csv.\")\n","\n","print(\"\\n=== Analysis Complete ===\")\n","print(\"CSV outputs generated, including 'filtered_cases.csv', 'anova_overall_results.csv'.\")\n","print(\"Now proceed with the plotting steps below.\")\n","\n","df_incidents = pd.read_csv(\"incidents_normalized.csv\")   # \"merged\"\n","df_severity = pd.read_csv(\"severity_by_year.csv\")        # \"severity_by_ntsb\"\n","df_exploded = pd.read_csv(\"filtered_cases.csv\")          # final main dataset\n","anova_df = pd.read_csv(\"anova_overall_results.csv\")      # ANOVA results\n","\n","print(\"Data loaded. Plot Generation Ready...\")"],"metadata":{"id":"O5re3ZCrod-n","executionInfo":{"status":"aborted","timestamp":1744850723679,"user_tz":360,"elapsed":8402,"user":{"displayName":"Nicholas Darden","userId":"15963773907732293009"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#==========================================================================================\n","# 5) Visualization"],"metadata":{"id":"wz35HO6Vtxhc"}},{"cell_type":"code","source":[],"metadata":{"id":"rlIXLDNowdAF","executionInfo":{"status":"aborted","timestamp":1744850723680,"user_tz":360,"elapsed":8403,"user":{"displayName":"Nicholas Darden","userId":"15963773907732293009"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Time Trend: Incidents per Million Flights"],"metadata":{"id":"I5ds9q-Dul8F"}},{"cell_type":"code","source":["\n","plt.figure(figsize=(10, 6))\n","plt.plot(\n","    df_incidents[\"Year\"],\n","    df_incidents[\"Incidents per Million Flights\"],\n","    marker=\"o\",\n","    linewidth=2\n",")\n","plt.title(\"U.S. Commercial Aviation Incident Rate per Million Flights\")\n","plt.xlabel(\"Year\")\n","plt.ylabel(\"Incidents per Million Flights\")\n","plt.xticks(df_incidents[\"Year\"], rotation=45)\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"j0wq6Q0uufD_","executionInfo":{"status":"aborted","timestamp":1744850723681,"user_tz":360,"elapsed":8402,"user":{"displayName":"Nicholas Darden","userId":"15963773907732293009"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Distribution: Highest Injury Level"],"metadata":{"id":"2ZML7anPunj1"}},{"cell_type":"code","source":["injury_counts = df_exploded[\"HighestInjuryLevel\"].value_counts()\n","plt.figure(figsize=(8, 8))\n","ordered_labels = [\"No Injury\", \"Minor\", \"Serious\", \"Fatal\"]\n","ordered_counts = [injury_counts.get(label, 0) for label in ordered_labels]\n","plt.pie(\n","    ordered_counts,\n","    labels=ordered_labels,\n","    autopct='%1.1f%%',\n","    startangle=0,\n","    counterclock=False,\n","    wedgeprops={'width': 0.4},\n","    pctdistance=0.75\n",")\n","plt.title(\"Distribution of Injury Levels in Incidents\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"mPl-D_RCu4mV","executionInfo":{"status":"aborted","timestamp":1744850723681,"user_tz":360,"elapsed":8401,"user":{"displayName":"Nicholas Darden","userId":"15963773907732293009"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Average Severity Score by Year"],"metadata":{"id":"d_YQ4LzNvaNx"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","plt.plot(\n","    df_severity[\"Year\"],\n","    df_severity[\"mean\"],\n","    marker=\"s\",\n","    color=\"darkred\"\n",")\n","plt.title(\"Average Severity Score per Incident by Year\")\n","plt.xlabel(\"Year\")\n","plt.ylabel(\"Avg Severity Score\")\n","plt.xticks(df_severity[\"Year\"], rotation=45)\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"xFkzF1L1vef6","executionInfo":{"status":"aborted","timestamp":1744850723682,"user_tz":360,"elapsed":8401,"user":{"displayName":"Nicholas Darden","userId":"15963773907732293009"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Severity per Million Flights by Year"],"metadata":{"id":"-qSIKB5vxHI_"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","plt.plot(\n","    df_severity[\"Year\"],\n","    df_severity[\"Severity per Million Flights\"],\n","    marker=\"s\",\n","    color=\"purple\"\n",")\n","plt.title(\"Severity per Million Flights by Year\")\n","plt.xlabel(\"Year\")\n","plt.ylabel(\"Severity per Million Flights\")\n","plt.xticks(df_severity[\"Year\"], rotation=45)\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"r3X_IRAtxKLN","executionInfo":{"status":"aborted","timestamp":1744850723683,"user_tz":360,"elapsed":8400,"user":{"displayName":"Nicholas Darden","userId":"15963773907732293009"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["State-Level Choropleths"],"metadata":{"id":"wRcIBnQsxeUg"}},{"cell_type":"code","source":["df_state = df_exploded.dropna(subset=[\"StateAbbrev\", \"Year\"]).copy()\n","df_by_state = (\n","    df_state.groupby([\"StateAbbrev\", \"Year\"], observed=False)[\"SeverityScore\"]\n","    .sum()\n","    .reset_index()\n",")\n","\n","severity_min = df_by_state[\"SeverityScore\"].min()\n","severity_max = df_by_state[\"SeverityScore\"].max()\n","\n","fig_choropleth = px.choropleth(\n","    df_by_state,\n","    locations=\"StateAbbrev\",\n","    locationmode=\"USA-states\",\n","    color=\"SeverityScore\",\n","    scope=\"usa\",\n","    animation_frame=\"Year\",\n","    color_continuous_scale=\"OrRd\",\n","    range_color=(severity_min, severity_max),\n","    labels={\"SeverityScore\": \"Severity\"},\n","    title=\"U.S. States Incident Severity by Year (Summed)\"\n",")\n","fig_choropleth.show()\n","\n","df_all_years = (\n","    df_by_state.groupby(\"StateAbbrev\", observed=False)[\"SeverityScore\"]\n","    .sum()\n","    .reset_index()\n",")\n","severity_min_all = df_all_years[\"SeverityScore\"].min()\n","severity_max_all = df_all_years[\"SeverityScore\"].max()\n","\n","fig_choropleth_all = px.choropleth(\n","    df_all_years,\n","    locations=\"StateAbbrev\",\n","    locationmode=\"USA-states\",\n","    color=\"SeverityScore\",\n","    scope=\"usa\",\n","    color_continuous_scale=\"OrRd\",\n","    range_color=(severity_min_all, severity_max_all),\n","    labels={\"SeverityScore\": \"Severity (All Years)\"},\n","    title=\"U.S. States Incident Severity (All Years Summed)\"\n",")\n","fig_choropleth_all.show()"],"metadata":{"id":"fV2QmyHPxeyL","executionInfo":{"status":"aborted","timestamp":1744850723683,"user_tz":360,"elapsed":8398,"user":{"displayName":"Nicholas Darden","userId":"15963773907732293009"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#6.) Factor Plots"],"metadata":{"id":"AWckO7YQyTYx"}},{"cell_type":"code","source":["# 4F. Interactive Choice of Factor for Violin & Stacked Bar Chart\n","if anova_df.empty:\n","    print(\"No ANOVA results found in 'anova_overall_results.csv'. Exiting.\")\n","else:\n","    anova_df_sorted = anova_df.sort_values(\"p_value\", ascending=True).reset_index(drop=True)\n","\n","    print(\"\\n--- ANOVA Results (From 'anova_overall_results.csv') ---\")\n","    print(\"All tested factors with p-values:\")\n","    for i, row in anova_df_sorted.iterrows():\n","        fct, p_val = row[\"Factor\"], row[\"p_value\"]\n","        print(f\" {i+1}. {fct} (p={p_val:.5f})\")\n","\n","    choice = input(\"\\nEnter the number of the factor you'd like to plot (e.g., '1'): \")\n","    try:\n","        choice_idx = int(choice) - 1\n","        if choice_idx < 0 or choice_idx >= len(anova_df_sorted):\n","            raise ValueError\n","        selected_factor = anova_df_sorted.loc[choice_idx, \"Factor\"]\n","    except ValueError:\n","        print(\"Invalid choice, defaulting to the first row in anova_df.\")\n","        selected_factor = anova_df_sorted.loc[0, \"Factor\"]\n","\n","    print(f\"\\nUsing factor: {selected_factor}\")\n","\n","    df_factor = df_exploded.dropna(subset=[\"SeverityScore\", selected_factor]).copy()\n","\n","    # Identify top 3 categories by mean SeverityScore\n","    top_categories = (\n","        df_factor[df_factor[selected_factor] != \"Unknown\"]\n","        .groupby(selected_factor, observed=False)[\"SeverityScore\"]\n","        .mean()\n","        .sort_values(ascending=False)\n","        .head(3)\n","        .index\n","    )\n","    df_top3 = df_factor[df_factor[selected_factor].isin(top_categories)].copy()\n","\n","    # --- Violin Chart ---\n","    plt.figure(figsize=(9, 6))\n","    sns.violinplot(\n","        data=df_top3,\n","        x=selected_factor,\n","        y=\"SeverityScore\",\n","        hue=selected_factor,\n","        dodge=False,\n","        inner=\"quartile\",\n","        palette=\"Pastel1\",\n","        legend=False\n","    )\n","    plt.title(f\"Violin Chart: Top 3 '{selected_factor}' by Mean SeverityScore\")\n","    plt.xlabel(selected_factor)\n","    plt.ylabel(\"SeverityScore\")\n","    plt.grid(axis='y', linestyle='--', alpha=0.7)\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # --- Stacked Bar Chart ---\n","    pivot_severity = (\n","        df_top3.groupby([\"Year\", selected_factor], observed=False)[\"SeverityScore\"]\n","        .sum()\n","        .unstack(fill_value=0)\n","    )\n","\n","    all_years = sorted(df_factor[\"Year\"].dropna().unique())\n","    pivot_severity = pivot_severity.reindex(all_years, fill_value=0)\n","    pivot_severity = pivot_severity.sort_index()\n","\n","    plt.figure(figsize=(12, 6))\n","    ax = plt.gca()\n","    pivot_severity.plot(\n","        kind=\"bar\",\n","        stacked=True,\n","        colormap=\"viridis\",\n","        ax=ax,\n","        width=0.8\n","    )\n","    ax.set_xticklabels(pivot_severity.index, rotation=45)\n","    ax.set_title(\n","        f\"Stacked Bar: Total Severity per Year for Top 3 '{selected_factor}'\"\n","    )\n","    ax.set_xlabel(\"Year\")\n","    ax.set_ylabel(\"Total Severity Score\")\n","    ax.legend(loc=\"best\")\n","    plt.tight_layout()\n","    plt.show()\n","\n","print(\"\\n=== Plotting Complete. ===\")"],"metadata":{"id":"Ppbx3PTeyfx-","executionInfo":{"status":"aborted","timestamp":1744850723684,"user_tz":360,"elapsed":8398,"user":{"displayName":"Nicholas Darden","userId":"15963773907732293009"}}},"execution_count":null,"outputs":[]}]}